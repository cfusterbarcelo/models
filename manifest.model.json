
{
    "name": "DeepImageJ Bundled Model Repository",
    "description": "Models available on the deepImageJ web site.",
    "version": "0.3.0",
    "models": [
      {
        "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/fru-net_sev_segmentation",
        "name": "Fully Residual U-Net - TEM",
        "description": "DeepImageJ compatible fully residual U-Net trained to segment small extracellular vesicles in 2D TEM images",
        "cite": [
          {
            "text": "G\u00f3mez-de-Mariscal, E. et al., Deep-Learning-Based Segmentation of SmallExtracellular Vesicles in Transmission Electron Microscopy Images Scientific Reports, (2019)",
            "doi": "https://doi.org/10.1038/s41598-019-49431-3"
          }
        ],
        "authors": [
          "Estibaliz G\u00f3mez-de-Mariscal",
          "Martin Ma\u0161ka, Anna Kotrbov\u00e1",
          "Vendula Posp\u00edchalov\u00e1",
          "Pavel Matula",
          "Arrate Mu\u00f1oz-Barrutia"
        ],
        "documentation": "https://cbia.fi.muni.cz/research/segmentation/fru-net.html",
        "covers": [
          "frunet_sev.jpg"
        ],
        "tags": [
          "deepimagej",
          "extracellular vesicles",
          "segmentation",
          "TEM"
        ],
        "license": "BSD 3",
        "config_url": "https://raw.githubusercontent.com/deepimagej/models/master/fru-net_sev_segmentation/FRUNet2DsEVSegmentation.model.yaml",
        "download_url": "https://zenodo.org/record/4156050/files/deepimagej_fru-net_sev_segmentation.zip"
      },
      {
        "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/u-net_hela_segmentation",
        "name": "U-Net Hela Cell Segmentation",
        "description": "DeepImageJ compatible U-Net trained to segment Hela cells in 2D phase contrast microscopy images",
        "cite": [
          {
            "text": "Biomedical Imaging Group, School of Engineering, Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne, Lausanne, Switzerland",
            "doi": null
          }
        ],
        "authors": [
          "Jo\u00e3o Soares Lopes"
        ],
        "documentation": "https://deepimagej.github.io/deepimagej/models_documentation.html",
        "covers": [
          "unet_hela_seg.jpg"
        ],
        "tags": [
          "deepimagej",
          "segmentation",
          "hela cells",
          "phase contrast"
        ],
        "license": "BSD-2",
        "git_repo": "https://github.com/deepimagej/python4deepimagej/tree/master/unet",
        "config_url": "https://raw.githubusercontent.com/deepimagej/models/master/u-net_hela_segmentation/UNet2DHelaSegmentation.model.yaml",
        "download_url": "https://zenodo.org/record/4155785/files/deepimagej_u-net_hela_segmentation.zip"
      },
      {
        "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/u-net_pancreatic_segmentation",
        "name": "U-Net Pancreatic Cell Segmentation",
        "description": "DeepImageJ compatible U-Net trained to segment phase contrast microscopy images of pancreatic stem cells on a 2D polystyrene substrate.",
        "cite": [
          {
            "text": "G\u00f3mez-de-Mariscal E. et al., biorXiv 2019",
            "doi": "https://doi.org/10.1101/799270"
          },
          {
            "text": "Ulman V. et al., Nature Methods 2017",
            "doi": "https://doi.org/10.1038/nmeth.4473"
          },
          {
            "text": "Ronneberger O. et al., MICCAI 2015",
            "doi": "https://doi.org/10.1007/978-3-319-24574-4_28"
          }
        ],
        "authors": [
          "Ignacio Arganda-Carreras",
          "DeepImageJ team"
        ],
        "documentation": "https://deepimagej.github.io/deepimagej/models_documentation.html",
        "covers": [
          "exampleImage.png",
          "resultImage.png"
        ],
        "tags": [
          "deepimagej",
          "segmentation",
          "pancreatic stem cells",
          "phase contrast"
        ],
        "license": "BSD-2",
        "config_url": "https://raw.githubusercontent.com/deepimagej/models/master/u-net_pancreatic_segmentation/UNet2DPancreaticSegmentation.model.yaml",
        "download_url": "https://github.com/deepimagej/models/releases/download/0.3/u-net_pancreatic_segmentation.zip"
      },
      {
        "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/u-net_glioblastoma_segmentation",
        "name": "U-Net GLioblastoma Cell Segmentation",
        "description": "DeepImageJ compatible U-Net trained to segment 2D phase contrast microscopy images of glioblastoma-astrocytoma U373 cells on a polyacrylamide substrate.",
        "cite": [
          {
            "text": "Biomedical Imaging Group, School of Engineering, Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne, Lausanne, Switzerland",
            "doi": null
          }
        ],
        "authors": [
          "Jo\u00e3o Soares Lopes"
        ],
        "documentation": "https://deepimagej.github.io/deepimagej/models_documentation.html",
        "covers": [
          "cover_image.jpg"
        ],
        "tags": [
          "deepimagej",
          "segmentation",
          "phase contrast",
          "glioblastoma cells"
        ],
        "license": "BSD-2",
        "git_repo": "https://github.com/deepimagej/python4deepimagej/tree/master/unet",
        "config_url": "https://raw.githubusercontent.com/deepimagej/models/master/u-net_glioblastoma_segmentation/UNet2DGlioblastomaSegmentation.model.yaml",
        "download_url": "https://zenodo.org/record/4155785/files/deepimagej_u-net_glioblastoma_segmentation.zip"
      },
      {
        "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/defcon_density_map_estimation",
        "name": "DEFCoN density map estimation",
        "description": "Density Estimation by Fully Convolutional Networks (DEFCoN) - A fluorescent spot counter for single molecule localization microscopy.",
        "cite": [
          {
            "text": "DEFCoN was written by Baptiste Ottino as a Master's thesis project under the guidance of Kyle M. Douglass and Suliana Manley in the Laboratory of Experimental Biophysics."
          }
        ],
        "authors": [
          "Baptiste Ottino",
          "Kyle M. Douglass",
          "Suliana Manley"
        ],
        "documentation": "https://github.com/LEB-EPFL/DEFCoN-ImageJ/wiki",
        "covers": [
          "cover_image.jpg"
        ],
        "tags": [
          "deepimagej",
          "defcon",
          "smlm",
          "density estimation"
        ],
        "license": "BSD 3",
        "git_repo": "https://github.com/LEB-EPFL/DEFCoN",
        "config_url": "https://raw.githubusercontent.com/deepimagej/models/master/defcon_density_map_estimation/DEFCoN_DensityMapEstimation.model.yaml",
        "download_url": "https://zenodo.org/record/4269855/files/deepimagej_defcon_density_map_estimation.zip"
      },
      {
        "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/deepstorm_zerocostdl4mic",
        "name": "DeepSTORMZeroCostDL4Mic",
        "description": "A trained Deep-STORM model for image reconstruction from high-density single-molecule localization microscopy (SMLM)",
        "cite": [
            {
                "text": "Lucas von Chamier et al. bioRxiv 2020",
                "doi": "https://doi.org/10.1101/2020.03.20.000133"
              },
              {
                "text": "\u00d6zg\u00fcn \u00c7i\u00e7ek et al., MICCAI 2016",
                "doi": "https://doi.org/10.1007/978-3-319-46723-8_49"
              }
         ],
         "authors": [
        "DeepImageJ Team"
          ],
      "documentation": "https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki",
      "covers": [
         "input.png",
         "zoom.png"
       ],
       "tags": [
         "zerocostdl4mic",
             "deepimagej",
             "smlm",
             "image-reconstruction",
             "super-resolution"
           ],
       "license": "MIT",
       "git_repo":"https://github.com/HenriquesLab/ZeroCostDL4Mic",
       "config_url":"https://raw.githubusercontent.com/deepimagej/models/master/defcon_density_map_estimation/ZeroCostDL4Mic.model.yaml",
       "download_url":"https://zenodo.org/record/5059813/files/HenriquesLab/ZeroCostDL4Mic-v1.13.zip"  
      },
      {
        "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/2du-net_zerocostdl4mic/",
        "name": "2DUNetZeroCostDL4Mic",
        "description": "2D U-Net trained for binary segmentation using the EM images of neuronal membranes and segmentation masks from the ISBI segmentation challenge 2012.",
        "cite": [
           {
                "text": "Ronneberger O. et al., MICCAI 2015",
                "doi": "https://doi.org/10.1007/978-3-319-24574-4_28"
              },
              {
                "text": "Lucas von Chamier et al. bioRxiv 2020",
                "doi": "https://doi.org/10.1101/2020.03.20.000133"
              },
              {
                "text": "G\u00f3mez de Mariscal et al. bioRxiv 2019",
                "doi": "https://doi.org/10.1101/799270"
              }
        ],
        "authors": [
            "ZeroCostDL4Mic team",
            "DeepImageJ team"
        ],
        "documentation": "https://deepimagej.github.io/deepimagej",
        "covers": [
          "cover.png"
        ],
        "tags": [
            "deepimagej",
            "zerocostdl4mic",
            "unet",
            "segmentation"
        ],
        "license": "MIT",
        "config_url": "https://raw.githubusercontent.com/deepimagej/models/master/2du-net_zerocostdl4mic/2du-net_zerocostdl4mic.model.yaml",
        "download_url": "https://zenodo.org/record/4155785/files/DeepImageJ_2D%20UNet_ZeroCostDL4Mic.zip"
      },
      {
        "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/mu-lux_ctc_phc-c2dl-psc",
        "name": "Pancreatic Cell Phase Contrast Segmentation (DeepWater - CTC submission)",
        "description": "The method combines deep learning with watershed segmentation. For each frame, the convolutional neural network of U-Net shape detects all cells by markers and recognizes the foreground and the background of the frame. Then, the final segmentation is generated by a Marker-Controlled Watershed transformation.",
        "cite": [
            {
                "text": "Ulman V. et al., Nature Methods 2017",
                "doi": "https://doi.org/10.1038/nmeth.447"
              },
              {
                "text": "Filip Lux and Petr Matula, arXiv 2020",
                "doi": "https://arxiv.org/abs/2004.01607"
              }
        ],
        "authors": [
            "Filip Lux, Centre for Biomedical Image Analysis, Masaryk University",
            "Petr Matula, Centre for Biomedical Image Analysis, Masaryk University"
        ],
        "documentation": "http://public.celltrackingchallenge.net/participants/MU-Lux-CZ.pdf",
        "covers": [
            "cover.jpg"
        ],
        "tags": [
            "deepimagej",
            "cell tracking challenge",
            "deepwater",
            "phase contrast",
            "watershed",
            "segmentation"
        ],
        "license": "MIT",
        "config_url": "https://raw.githubusercontent.com/deepimagej/models/master/mu-lux_ctc_phc-c2dl-psc/mu-lux_ctc_phc-c2dl-psc.model.yaml",
        "download_url": "https://zenodo.org/record/4155785/files/MU-Lux_CTC_PhC-C2DL-PSC.bioimage.io.model.zip"
      },
      {
        "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/widefield_txred_super-resolution",
        "name": "Widefield Super-resolution (GAN - TxRed)",
        "description": "A trained GAN to transform diffraction-limited input images into super-resolved ones.",
        "cite": [
            {
                "text": "Hongda Wang, Yair Rivenson, et al., Nature Methods 2019",
                "doi": "https://doi.org/10.1038/s41592-018-0239-0"
              }
        ],
        "authors": [
            "Hongda Wang",
            "Yair Rivenson",
            "Aydogan Ozcan"
        ],
        "documentation": "https://innovate.ee.ucla.edu",
        "covers": [
            "exampleImage.png",
            "resultImage.png"
        ],
        "tags": [
            "deepimagej",
            "Super resolution",
            "GAN",
            "Fluorescence microscopy"
        ],
        "license": "CC BY 4.0",
        "config_url": "https://raw.githubusercontent.com/deepimagej/models/master/widefield_txred_super-resolution/widefield_txred_super-resolution.model.yaml",
        "download_url": "https://sandbox.zenodo.org/record/913992/files/widefield_txred_super-resolution.zip"
      },
      {
        "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/widefield_dapi_super-resolution",
        "name": "Widefield Super-resolution (GAN - DAPI)",
        "description": "A trained GAN to transform diffraction-limited input images into super-resolved ones.",
        "cite": [
            {
                "text": "Hongda Wang, Yair Rivenson, et al., Nature Methods 2019",
                "doi": "https://doi.org/10.1038/s41592-018-0239-0"
              }
        ],
        "authors": [
            "Hongda Wang",
            "Yair Rivenson",
            "Aydogan Ozcan"
        ],
        "documentation": "https://innovate.ee.ucla.edu",
        "covers": [
            "exampleImage.png",
            "resultImage.png"
        ],
        "tags": [
            "deepimagej",
            "Super resolution",
            "GAN",
            "Fluorescence microscopy"
        ],
        "license": "CC BY 4.0",
        "config_url": "https://raw.githubusercontent.com/deepimagej/models/master/widefield_dapi_super-resolution/widefield_dapi_super-resolution.model.yaml",
        "download_url": "https://zenodo.org/record/4290871/files/widefield_dapi_superresolution.bioimage.io.model.zip"
      },
      {
        "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/widefield_fitc_super-resolution",
        "name": "Widefield Super-resolution (GAN - FITC)",
        "description": "A trained GAN to transform diffraction-limited input images into super-resolved ones.",
        "cite": [
            {
                "text": "Hongda Wang, Yair Rivenson, et al., Nature Methods 2019",
                "doi": "https://doi.org/10.1038/s41592-018-0239-0"
              }
        ],
        "authors": [
            "Hongda Wang",
            "Yair Rivenson",
            "Aydogan Ozcan"
        ],
        "documentation": "https://innovate.ee.ucla.edu",
        "covers": [
            "exampleImage.png",
            "resultImage.png"
        ],
        "tags": [
            "deepimagej",
            "Super resolution",
            "GAN",
            "Fluorescence microscopy"
        ],
        "license": "CC BY 4.0",
        "config_url": "https://raw.githubusercontent.com/deepimagej/models/master/widefield_fitc_super-resolution/widefield_fitc_super-resolution.model.yaml",
        "download_url": "https://zenodo.org/record/4290871/files/widefield_fitc_super-resolution.bioimage.io.model.zip"
      },
      {
        "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/jones_virtual_staining",
        "name": "Jones Virtual Staining (GAN)",
        "description": "A trained GAN to transform wide-field autofluorescence images of unlabelled tissue sections into images that are equivalent to the bright-field images of histologically stained versions of the same samples.",
        "cite": [
          {
            "text": "Hongda Wang, Yair Rivenson, et al., Nature Biomedical Engineering, 2019",
            "doi": "https://doi.org/10.1038/s41551-019-0362-y"
          }
        ],
        "authors": [
          "Yair Rivenson",
          "Hongda Wang",
          "Aydogan Ozcan"
        ],
        "documentation": "https://innovate.ee.ucla.edu",
        "covers": [
            "exampleImage.png",
            "resultImage.png"
        ],
        "tags": [
          "deepimagej",
          "GAN",
          "Virtual staining",
          "histology"
        ],
        "license": "CC BY 4.0",
        "config_url": "https://raw.githubusercontent.com/deepimagej/models/master/jones_virtual_staining/jones_virtual_staining.model.yaml",
        "download_url": "https://zenodo.org/record/4290839/files/jones_virtual_staining.bioimage.io.model.zip"
      },
      {
        "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/mt3_virtual_staining",
        "name": "Masson\u2019s Trichrome Virtual Staining (GAN)",
        "description": "A trained GAN to transform wide-field autofluorescence images of unlabelled tissue sections into images that are equivalent to the bright-field images of histologically stained versions of the same samples.",
        "cite": [
          {
            "text": "Hongda Wang, Yair Rivenson, et al., Nature Biomedical Engineering, 2019",
            "doi": "https://doi.org/10.1038/s41551-019-0362-y"
          }
        ],
        "authors": [
          "Yair Rivenson",
          "Hongda Wang",
          "Aydogan Ozcan"
        ],
        "documentation": "https://innovate.ee.ucla.edu",
        "covers": [
            "exampleImage.png",
            "resultImage.png"
        ],
        "tags": [
          "deepimagej",
          "GAN",
          "Virtual staining",
          "histology"
        ],
        "license": "CC BY 4.0",
        "config_url": "https://raw.githubusercontent.com/deepimagej/models/master/mt3_virtual_staining/mt3_virtual_staining.model.yaml",
        "download_url": "https://zenodo.org/record/4290839/files/mt3_virtual_staining.bioimage.io.model.zip"
      },
      {
        "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/usiigaci",
        "name": "NIH/3T3 Fibroblast Phase Contrast Segmentation (Usiigaci-Mask R-CNN)",
        "description": "Trained model given in Usiigaci for instance segmentation of cells in a 2D substrate and phase contrast microscopy images. The model is a Mask R-CNN and the input is preprocessed to get an RGB image from the grayscale image.",
        "cite": [
          {
            "text": "Tsai, H.-F., et al., SoftwareX, 2019",
            "doi": "https://doi.org/10.1016/j.softx.2019.02.007"
          }
        ],
        "authors": [
          "Joanna Gajda",
          "Tyler F.W. Sloan",
          "Hsieh-Fu Tsai",
          "Andrei Rares",
          "Amy Q. Shen"
        ],
        "documentation": "https://github.com/oist/Usiigaci",
        "covers": [
          "cover.jpg"
        ],
        "tags": [
          "deepimagej",
          "2D",
          "maskrcnn",
          "phase contrast",
          "deepimagej-beta",
          "usiigaci",
          "fibroblasts",
          "segmentation"
        ],
        "license": "MIT",
        "config_url": "https://raw.githubusercontent.com/deepimagej/models/master/usiigaci/usiigaci.model.yaml",
        "download_url": "https://zenodo.org/record/4155785/files/usiigaci.bioimage.io.model.zip"
      },
      {
        "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/skin_lesion_classification",
        "name": "Skin lesions classification",
        "description": "CNN trained to classify the type of imaged skin lesion.",
        "authors": [
          "Carlos Garc\u00eda-L\u00f3pez-de-Haro"
        ],
        "documentation": "https://gist.github.com/esgomezm/7398a83321ae589bafadb0392c7b78ef#file-skin_lession_classification_pytorch_original-ipynb",
        "covers": [
          "cover.jpg"
        ],
        "tags": [
          "deepimagej",
          "skin lesions",
          "deepimagej-beta",
          "melanoma",
          "classification",
          "pytorch"
        ],
        "license": "BSD2",
        "config_url": "https://raw.githubusercontent.com/deepimagej/models/master/skin_lesion_classification/skin_lesion_classification.model.yaml",
        "download_url": "https://zenodo.org/record/4155785/files/SkinLesions.bioimage.io.model.zip"
      },
      {
        "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/3du-net_zerocostdl4mic",
        "name": "3D U-Net - ZeroCostDL4Mic",
        "description": "3D U-Net trained using ZeroCostDL4Mic notebooks to segment mitochondria in Transmission Electron Microscopy (TEM) data.",
        "cite": [
          {
            "text": "Lucas von Chamier et al. bioRxiv 2020",
            "doi": "https://doi.org/10.1101/2020.03.20.000133"
          },
          {
            "text": "\u00d6zg\u00fcn \u00c7i\u00e7ek et al., MICCAI 2016",
            "doi": "https://doi.org/10.1007/978-3-319-46723-8_49"
          }
        ],
        "authors": [
          "DeepImageJ team"
        ],
        "documentation": "https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki",
        "covers": [
          "exampleImage.gif"
        ],
        "tags": [
          "deepimagej",
          "ZeroCostDL4Mic",
          "3DUNet",
          "deepimagej-beta",
          "mitochondria",
          "TEM",
          "segmentation"
        ],
        "license": "MIT",
        "config_url": "https://raw.githubusercontent.com/deepimagej/models/master/3du-net_zerocostdl4mic/3du-net_zerocostdl4mic.model.yaml",
        "download_url": "https://zenodo.org/record/4155785/files/3DUNet_ZeroCostDL4Mic.bioimage.io.model.zip"
      }             
    ]
  }