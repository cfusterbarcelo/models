{
  "id": "deepimagej",
  "name": "DeepImageJ",
  "tags": [
    "deepimagej"
  ],
  "logo": "https://raw.githubusercontent.com/deepimagej/models/master/logos/logo.png",
  "icon": "https://raw.githubusercontent.com/deepimagej/models/master/logos/icon.png",
  "splash_title": "deepImageJ",
  "splash_subtitle": "A user-friendly plugin to run deep learning models in ImageJ",
  "splash_feature_list": null,
  "explore_button_text": "Start Exploring",
  "background_image": "static/img/zoo-background.svg",
  "resource_types": [
    "model",
    "notebook",
    "application"
  ],
  "url_root": "https://raw.githubusercontent.com/deepimagej/models/master",
  "collections": [],
  "resources": [
    {
      "id": "deepimagej/deepimagej",
      "type": "application",
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/src/deepimagej-app.imjoy.html",
      "passive": false,
      "icon": "https://raw.githubusercontent.com/deepimagej/models/master/logos/icon.png",
      "name": "deepimagej",
      "version": "2.1.10",
      "api_version": "0.1.0",
      "description": "Export BioImage.IO model packages for deepImageJ from a model description file",
      "requirements": [
        "https://cdnjs.cloudflare.com/ajax/libs/vue/2.5.22/vue.min.js",
        "https://static.imjoy.io/spectre.css/spectre.min.css",
        "https://static.imjoy.io/spectre.css/spectre-exp.min.css",
        "https://static.imjoy.io/spectre.css/spectre-icons.min.css",
        "https://static.imjoy.io/js/UZIP.js",
        "https://cdnjs.cloudflare.com/ajax/libs/js-yaml/4.0.0/js-yaml.min.js",
        "https://cdnjs.cloudflare.com/ajax/libs/axios/0.19.2/axios.min.js"
      ],
      "dependencies": [],
      "env": "",
      "tags": [
        "bioengine",
        "software"
      ],
      "documentation": null,
      "covers": [],
      "badges": [],
      "authors": []
    },
    {
      "id": "deepimagej/EVsTEMsegmentationFRUNet",
      "type": "application",
      "name": "Small extracellular vesicle instance segmentation (FRU-Net)",
      "description": "Ready to use notebook for the segmentation of small extrcaellular vesicles in transmission electron microscopy (TEM) images. The notebook is optimized to use it in Google Colaboratory. It will download the original code and dataset, and make the inference connecting with Google's GPU.",
      "cite": [
        {
          "text": "G\u00f3mez-de-Mariscal, E. et al., Deep-Learning-Based Segmentation of SmallExtracellular Vesicles in Transmission Electron Microscopy Images Scientific Reports, (2019)",
          "doi": "https://doi.org/10.1038/s41598-019-49431-3"
        }
      ],
      "authors": [
        "Estibaliz G\u00f3mez-de-Mariscal",
        "Martin Ma\u0161ka, Anna Kotrbov\u00e1",
        "Vendula Posp\u00edchalov\u00e1",
        "Pavel Matula",
        "Arrate Mu\u00f1oz-Barrutia"
      ],
      "covers": [
        "https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs41598-019-49431-3/MediaObjects/41598_2019_49431_Fig1_HTML.png",
        "https://raw.githubusercontent.com/deepimagej/models/master/fru-net_sev_segmentation/frunet_sev.jpg"
      ],
      "badges": [
        {
          "label": "Open in Colab",
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "url": "https://colab.research.google.com/github/BIIG-UC3M/FRU-Net-TEM-segmentation/blob/main/FRUnet_TEM_Exosomes_sEV.ipynb"
        }
      ],
      "documentation": "https://cbia.fi.muni.cz/research/segmentation/fru-net.html",
      "tags": [
        "pipeline",
        "extracellular vesicles",
        "notebook",
        "TEM",
        "model inference",
        "google colab",
        "segmentation",
        "workflow"
      ],
      "source": "https://raw.githubusercontent.com/BIIG-UC3M/FRU-Net-TEM-segmentation/master/FRUnet_TEM_Exosomes_sEV.ipynb",
      "links": [
        "deepimagej/FRUNet2DsEVSegmentation"
      ]
    },
    {
      "id": "deepimagej/smlm-deepimagej",
      "type": "application",
      "name": "SMLM-superresolution",
      "description": "Single molecule localization microscopy (SMLM) processing using deepImageJ and ThunderSTORM in an ImageJ macro.",
      "covers": [
        "https://raw.githubusercontent.com/deepimagej/models/master/workflows/smlm_deepstorm/cover.png"
      ],
      "download_url": "https://raw.githubusercontent.com/deepimagej/imagej-macros/master/DeepSTORM4stacksThunderSTORM.ijm",
      "source": "https://raw.githubusercontent.com/deepimagej/imagej-macros/master/DeepSTORM4stacksThunderSTORM.ijm",
      "cite": [
        {
          "text": "Lucas von Chamier et al., Nature Communications 2021",
          "doi": "https://doi.org/10.1038/s41467-021-22518-0"
        },
        {
          "text": "G\u00f3mez de Mariscal et al. bioRxiv 2019",
          "doi": "https://doi.org/10.1101/799270"
        },
        {
          "text": "M. Ovesn\u00fd, et al., Bioinformatics 2014",
          "doi": "https://doi.org/10.1093/bioinformatics/btu202"
        }
      ],
      "authors": [
        "DeepImageJ team, UC3M, EPFL"
      ],
      "icon": "https://raw.githubusercontent.com/deepimagej/models/master/logos/icon.png",
      "documentation": "https://raw.githubusercontent.com/deepimagej/models/master/workflows/smlm_deepstorm/README.md",
      "tags": [
        "thunderstorm",
        "smlm",
        "pipeline",
        "deepimagej",
        "superresolution",
        "workflow",
        "deepstorm",
        "macro"
      ]
    },
    {
      "id": "deepimagej/deepimagej-web",
      "type": "application",
      "name": "DeepImageJ",
      "description": "DeepImageJ is a user-friendly plugin that enables the use of pre-trained deep learning models in ImageJ and Fiji.",
      "source": "https://deepimagej.github.io/deepimagej/index.html",
      "cite": {
        "text": "G\u00f3mez-de-Mariscal, E., Garc\u00eda-L\u00f3pez-de-Haro, C., Ouyang, W., Donati, L., Lundberg E., Unser, M., Mu\u00f1oz-Barrutia, A. and Sage, D. DeepImageJ: A user-friendly plugin to run deep learning models in ImageJ, BioRxiv, 2019",
        "doi": "https://doi.org/10.1101/799270"
      },
      "authors": [
        "DeepImageJ team"
      ],
      "icon": "https://raw.githubusercontent.com/deepimagej/models/master/logos/icon.png",
      "documentation": "https://deepimagej.github.io/deepimagej/index.html",
      "git_repo": "https://github.com/deepimagej/deepimagej-plugin",
      "passive": true,
      "tags": [
        "deepimagej",
        "software"
      ],
      "config": {
        "supported_weight_formats": [
          "tensorflow_saved_model_bundle"
        ]
      }
    },
    {
      "id": "deepimagej/unet-pancreaticcellsegmentation",
      "type": "application",
      "name": "2D U-Net for binary segmentation",
      "description": "Easy example to define a 2D U-Net for segmentation with Keras and import it into DeepImageJ format",
      "cite": [
        {
          "text": "Falk, T., Mai, D., Bensch, R. et al. U-Net: deep learning for cell counting, detection, and morphometry. Nat Methods 16, 67\u201370 (2019).",
          "doi": "https://doi.org/10.1038/s41592-018-0261-2"
        }
      ],
      "authors": [
        "Ignacio Arganda-Carreras",
        "DeepImageJ team"
      ],
      "covers": [
        "https://raw.githubusercontent.com/deepimagej/models/master/u-net_pancreatic_segmentation/notebook_intro.png",
        "https://raw.githubusercontent.com/deepimagej/models/master/u-net_pancreatic_segmentation/usecase.png"
      ],
      "badges": [
        {
          "label": "Open in Colab",
          "icon": "https://colab.research.google.com/assets/colab-badge.svg",
          "url": "https://colab.research.google.com/github/deepimagej/models/blob/master/u-net_pancreatic_segmentation/U_Net_PhC_C2DL_PSC_segmentation.ipynb"
        }
      ],
      "documentation": "https://github.com/miura/NEUBIAS_AnalystSchool2020/tree/master/Ignacio",
      "tags": [
        "deepimagej",
        "notebook",
        "training",
        "segmentation",
        "cell segmentation",
        "unet"
      ],
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/u-net_pancreatic_segmentation/U_Net_PhC_C2DL_PSC_segmentation.ipynb",
      "links": [
        "deepimagej/UNet2DPancreaticSegmentation"
      ]
    },
    {
      "type": "model",
      "attachments": {
        "files": [
          "./preprocessing.txt",
          "./postprocessing.txt",
          "./exampleImage.tif",
          "./resultImage.tif"
        ]
      },
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/widefield_txred_super-resolution/model.yaml",
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/widefield_txred_super-resolution",
      "id": "deepimagej/WidefieldTxredSuperResolution",
      "download_url": "https://zenodo.org/record/4290871/files/widefield_txred_superresolution.bioimage.io.model.zip",
      "links": [
        "deepimagej/deepimagej",
        "imjoy/BioImageIO-Packager"
      ],
      "format_version": "0.3.0",
      "name": "Widefield Super-resolution (GAN - TxRed)",
      "description": "A trained GAN to transform diffraction-limited input images into super-resolved ones.",
      "cite": [
        {
          "text": "Hongda Wang, Yair Rivenson, et al., Nature Methods 2019",
          "doi": "https://doi.org/10.1038/s41592-018-0239-0"
        }
      ],
      "authors": [
        "Hongda Wang",
        "Yair Rivenson",
        "Aydogan Ozcan"
      ],
      "covers": [
        "exampleImage.png",
        "resultImage.png"
      ],
      "tags": [
        "deepimagej",
        "GAN",
        "Super resolution",
        "Fluorescence microscopy"
      ],
      "documentation": "https://innovate.ee.ucla.edu",
      "license": "CC BY 4.0",
      "error": {}
    },
    {
      "type": "model",
      "attachments": {
        "files": [
          "./preprocessing.txt",
          "./postprocessing.txt",
          "./exampleImage.tif",
          "./resultImage.tif"
        ]
      },
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/widefield_fitc_super-resolution/model.yaml",
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/widefield_fitc_super-resolution",
      "id": "deepimagej/WidefieldFitcSuperResolution",
      "download_url": "https://zenodo.org/record/4290871/files/widefield_fitc_superresolution.bioimage.io.model.zip",
      "links": [
        "deepimagej/deepimagej",
        "imjoy/BioImageIO-Packager"
      ],
      "format_version": "0.3.0",
      "name": "Widefield Super-resolution (GAN - FITC)",
      "description": "A trained GAN to transform diffraction-limited input images into super-resolved ones.",
      "cite": [
        {
          "text": "Hongda Wang, Yair Rivenson, et al., Nature Methods 2019",
          "doi": "https://doi.org/10.1038/s41592-018-0239-0"
        }
      ],
      "authors": [
        "Hongda Wang",
        "Yair Rivenson",
        "Aydogan Ozcan"
      ],
      "covers": [
        "exampleImage.png",
        "resultImage.png"
      ],
      "tags": [
        "deepimagej",
        "GAN",
        "Super resolution",
        "Fluorescence microscopy"
      ],
      "documentation": "https://innovate.ee.ucla.edu",
      "license": "CC BY 4.0",
      "error": {}
    },
    {
      "type": "model",
      "attachments": {
        "files": [
          "./preprocessing.txt",
          "./postprocessing.txt",
          "./exampleImage.tif",
          "./resultImage.tif"
        ]
      },
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/widefield_dapi_super-resolution/model.yaml",
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/widefield_dapi_super-resolution",
      "id": "deepimagej/WidefieldDapiSuperResolution",
      "download_url": "https://zenodo.org/record/4290871/files/widefield_dapi_superresolution.bioimage.io.model.zip",
      "links": [
        "deepimagej/deepimagej",
        "imjoy/BioImageIO-Packager"
      ],
      "format_version": "0.3.0",
      "name": "Widefield Super-resolution (GAN - DAPI)",
      "description": "A trained GAN to transform diffraction-limited input images into super-resolved ones.",
      "cite": [
        {
          "text": "Hongda Wang, Yair Rivenson, et al., Nature Methods 2019",
          "doi": "https://doi.org/10.1038/s41592-018-0239-0"
        }
      ],
      "authors": [
        "Hongda Wang",
        "Yair Rivenson",
        "Aydogan Ozcan"
      ],
      "covers": [
        "exampleImage.png",
        "resultImage.png"
      ],
      "tags": [
        "deepimagej",
        "GAN",
        "Super resolution",
        "Fluorescence microscopy"
      ],
      "documentation": "https://innovate.ee.ucla.edu",
      "license": "CC BY 4.0",
      "error": {}
    },
    {
      "type": "model",
      "attachments": {
        "files": [
          "./preprocessing.txt",
          "./exampleImage.tiff",
          "./resultImage.tiff",
          "./postprocessing.txt",
          "./postprocessingWatershed.txt"
        ]
      },
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/fru-net_sev_segmentation/model.yaml",
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/fru-net_sev_segmentation",
      "id": "deepimagej/FRUNet2DsEVSegmentation",
      "links": [
        "deepimagej/deepimagej",
        "deepimagej/EVsTEMsegmentationFRUNet",
        "imjoy/BioImageIO-Packager"
      ],
      "download_url": "https://sandbox.zenodo.org/record/894459/files/deepimagej_fru-net_sev_segmentation.zip",
      "format_version": "0.3.0",
      "name": "Small Extracellular Vesicle TEM Segmentation (Fully Residual U-Net)",
      "description": "DeepImageJ compatible fully residual U-Net trained to segment small extracellular vesicles in 2D TEM images",
      "cite": [
        {
          "text": "G\u00f3mez-de-Mariscal, E. et al., Deep-Learning-Based Segmentation of SmallExtracellular Vesicles in Transmission Electron Microscopy Images Scientific Reports, (2019)",
          "doi": "https://doi.org/10.1038/s41598-019-49431-3"
        }
      ],
      "authors": [
        "Estibaliz G\u00f3mez-de-Mariscal",
        "Martin Ma\u0161ka, Anna Kotrbov\u00e1",
        "Vendula Posp\u00edchalov\u00e1",
        "Pavel Matula",
        "Arrate Mu\u00f1oz-Barrutia"
      ],
      "documentation": "https://cbia.fi.muni.cz/research/segmentation/fru-net.html",
      "covers": [
        "frunet_sev.jpg"
      ],
      "tags": [
        "deepimagej",
        "segmentation",
        "TEM",
        "extracellular vesicles"
      ],
      "license": "BSD-3-Clause",
      "error": {}
    },
    {
      "type": "model",
      "attachments": {
        "files": [
          "./preprocessing.ijm",
          "./post.ijm",
          "./0066.tif",
          "./lesion.csv",
          "./0066_mask.png"
        ]
      },
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/skin_lesion_classification/model.yaml",
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/skin_lesion_classification",
      "id": "deepimagej/SkinLesionClassification",
      "download_url": "https://zenodo.org/record/4155785/files/SkinLesions.bioimage.io.model.zip",
      "links": [
        "deepimagej/deepimagej"
      ],
      "format_version": "0.3.1",
      "name": "Skin lesions classification",
      "description": "CNN trained to classify the type of imaged skin lesion.",
      "authors": [
        "Carlos Garc\u00eda-L\u00f3pez-de-Haro"
      ],
      "documentation": "https://gist.github.com/esgomezm/7398a83321ae589bafadb0392c7b78ef#file-skin_lession_classification_pytorch_original-ipynb",
      "covers": [
        "cover.jpg"
      ],
      "tags": [
        "melanoma",
        "pytorch",
        "classification",
        "deepimagej",
        "skin lesions",
        "deepimagej-beta"
      ],
      "license": "BSD2",
      "git_repo": "https://gist.github.com/esgomezm/72b584887ca5ed5ed0231c47fff9aa9b#file-skin_lession_classification_pytorch_adapted-ipynb",
      "error": {}
    },
    {
      "type": "model",
      "attachments": {
        "files": [
          "./preprocessing.txt",
          "./postprocessing.txt",
          "./exampleImage.tif",
          "./Results.csv",
          "./resultImage.tif"
        ]
      },
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/defcon_density_map_estimation/model.yaml",
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/defcon_density_map_estimation",
      "id": "deepimagej/SMLMDensityMapEstimationDEFCoN",
      "download_url": "https://zenodo.org/record/4608442/files/SMLM_Density%20Map_Estimation_%28DEFCoN%29.bioimage.io.model.zip",
      "links": [
        "deepimagej/deepimagej",
        "imjoy/BioImageIO-Packager"
      ],
      "format_version": "0.3.0",
      "name": "SMLM Density Map Estimation (DEFCoN)",
      "description": "Density Estimation by Fully Convolutional Networks (DEFCoN) - A fluorescent spot counter for single molecule localization microscopy. DEFCoN was written by Baptiste Ottino as a Masters thesis project under the guidance of Kyle M. Douglass and Suliana Manley in the Laboratory of Experimental Biophysics.",
      "cite": null,
      "authors": [
        "Baptiste Ottino",
        "Kyle M. Douglass",
        "Suliana Manley"
      ],
      "documentation": "https://github.com/LEB-EPFL/DEFCoN-ImageJ/wiki",
      "covers": [
        "cover_image.jpg"
      ],
      "tags": [
        "deepimagej",
        "unet",
        "deepimagej.js"
      ],
      "license": "BSD 3",
      "git_repo": "https://github.com/LEB-EPFL/DEFCoN",
      "error": {}
    },
    {
      "type": "model",
      "attachments": {
        "files": [
          "./preprocessing.txt",
          "./postprocessing.txt",
          "./exampleImage.tif",
          "./resultImage.tif"
        ]
      },
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/u-net_pancreatic_segmentation/model.yaml",
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/u-net_pancreatic_segmentation",
      "id": "deepimagej/UNet2DPancreaticSegmentation",
      "download_url": "https://github.com/deepimagej/models/releases/download/0.3/PancreaticCellSegmentation.U-Net.bioimage.io.model.zip",
      "links": [
        "deepimagej/deepimagej",
        "deepimagej/unet-pancreaticcellsegmentation",
        "imjoy/BioImageIO-Packager"
      ],
      "format_version": "0.3.0",
      "name": "Pancreatic Phase Contrast Cell Segmentation (U-Net)",
      "description": "DeepImageJ compatible U-Net trained to segment phase contrast microscopy images of pancreatic stem cells on a 2D polystyrene substrate.",
      "cite": [
        {
          "text": "G\u00f3mez-de-Mariscal E. et al., biorXiv 2019",
          "doi": "https://doi.org/10.1101/799270"
        },
        {
          "text": "Ulman V. et al., Nature Methods 2017",
          "doi": "https://doi.org/10.1038/nmeth.4473"
        },
        {
          "text": "Ronneberger O. et al., MICCAI 2015",
          "doi": "https://doi.org/10.1007/978-3-319-24574-4_28"
        }
      ],
      "authors": [
        "Ignacio Arganda-Carreras",
        "DeepImageJ team"
      ],
      "documentation": "https://github.com/deepimagej/models/u-net_pancreatic_segmentation/U_Net_PhC-C2DL-PSC_segmentation.ipynb",
      "git_repo": "https://github.com/deepimagej/models/u-net_pancreatic_segmentation/",
      "covers": [
        "exampleImage.png",
        "resultImage.png"
      ],
      "tags": [
        "deepimagej",
        "segmentation",
        "phase contrast",
        "pancreatic stem cells"
      ],
      "license": "BSD-2",
      "error": {}
    },
    {
      "type": "model",
      "attachments": {
        "files": [
          "./preprocessing.txt",
          "./postprocessing.txt",
          "./exampleImage.tiff",
          "./resultImage.tiff"
        ]
      },
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/mu-lux_ctc_phc-c2dl-psc/model.yaml",
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/mu-lux_ctc_phc-c2dl-psc",
      "id": "deepimagej/MU-Lux_CTC_PhC-C2DL-PSC",
      "download_url": "https://zenodo.org/record/4155785/files/MU-Lux_CTC_PhC-C2DL-PSC.bioimage.io.model.zip",
      "links": [
        "deepimagej/deepimagej",
        "imjoy/BioImageIO-Packager"
      ],
      "format_version": "0.3.0",
      "name": "Pancreatic Cell Phase Contrast Segmentation (DeepWater - CTC submission)",
      "description": "The method combines deep learning with watershed segmentation. For each frame, the convolutional neural network of U-Net shape detects all cells by markers and recognizes the foreground and the background of the frame. Then, the final segmentation is generated by a Marker-Controlled Watershed transformation.",
      "cite": [
        {
          "text": "Ulman V. et al., Nature Methods 2017",
          "doi": "https://doi.org/10.1038/nmeth.447"
        },
        {
          "text": "Filip Lux and Petr Matula, arXiv 2020",
          "doi": "https://arxiv.org/abs/2004.01607"
        }
      ],
      "authors": [
        "Filip Lux, Centre for Biomedical Image Analysis, Masaryk University",
        "Petr Matula, Centre for Biomedical Image Analysis, Masaryk University"
      ],
      "git_repo": "https://gitlab.fi.muni.cz/xlux/deepwater",
      "documentation": "http://public.celltrackingchallenge.net/participants/MU-Lux-CZ.pdf",
      "covers": [
        "cover.jpg"
      ],
      "tags": [
        "cell tracking challenge",
        "deepwater",
        "deepimagej",
        "phase contrast",
        "segmentation",
        "watershed"
      ],
      "license": "MIT",
      "error": {}
    },
    {
      "type": "model",
      "attachments": {
        "files": [
          "./preprocessing.ijm",
          "./postprocessing.ijm",
          "./General.jar",
          "./config.ijm",
          "./exampleImage.tif",
          "./MAX_finalMask.tif",
          "./fibroblasts_detection.csv"
        ]
      },
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/usiigaci/model.yaml",
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/usiigaci",
      "id": "deepimagej/Usiigaci",
      "download_url": "https://zenodo.org/record/4155785/files/usiigaci.bioimage.io.model.zip",
      "links": [
        "deepimagej/deepimagej",
        "imjoy/BioImageIO-Packager"
      ],
      "format_version": "0.3.1",
      "name": "NIH/3T3 Fibroblast Phase Contrast Segmentation (Usiigaci-Mask R-CNN)",
      "description": "Trained model given in Usiigaci for instance segmentation of cells in a 2D substrate and phase contrast microscopy images. The model is a Mask R-CNN and the input is preprocessed to get an RGB image from the grayscale image.",
      "cite": [
        {
          "text": "Tsai, H.-F., et al., SoftwareX, 2019",
          "doi": "https://doi.org/10.1016/j.softx.2019.02.007"
        }
      ],
      "authors": [
        "Joanna Gajda",
        "Tyler F.W. Sloan",
        "Hsieh-Fu Tsai",
        "Andrei Rares",
        "Amy Q. Shen"
      ],
      "covers": [
        "cover.jpg"
      ],
      "tags": [
        "2D",
        "deepimagej",
        "maskrcnn",
        "usiigaci",
        "deepimagej-beta",
        "phase contrast",
        "fibroblasts",
        "segmentation"
      ],
      "license": "MIT",
      "git_repo": "https://github.com/oist/Usiigaci",
      "error": {}
    },
    {
      "type": "dataset",
      "id": "deepimagej/MoNuSeg_digital_pathology_miccai2018",
      "name": "Multi-Organ Nucleus Segmentation Challenge - MICCAI 2018",
      "description": "Labelled images for instance segmentation of cell nuclei in digital pathology datasets (MoNuSeg 2018 Challenge).",
      "cite": {
        "text": "Neeraj Kumar et al. Transactions on medical imaging 2020",
        "doi": "https://doi.org/10.1109/TMI.2019.2947628"
      },
      "authors": [
        "DeepImageJ team, UC3M, EPFL"
      ],
      "documentation": "https://monuseg.grand-challenge.org",
      "tags": [
        "digital pathology",
        "H&E",
        "2D",
        "deepimagej",
        "histology",
        "pathology",
        "StarDist",
        "segmentation",
        "nuclei segmentation"
      ],
      "covers": [
        "https://raw.githubusercontent.com/deepimagej/models/master/datasets/MoNuSeg1.jpg",
        "https://raw.githubusercontent.com/deepimagej/models/master/datasets/MoNuSeg2.jpg",
        "https://raw.githubusercontent.com/deepimagej/models/master/datasets/MoNuSeg3.jpg"
      ],
      "source": "https://monuseg.grand-challenge.org/Data/"
    },
    {
      "type": "model",
      "attachments": {
        "files": [
          "./preprocessing.txt",
          "./postprocessing.txt",
          "./exampleImage.tif",
          "./resultImage.tif"
        ]
      },
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/mt3_virtual_staining/model.yaml",
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/mt3_virtual_staining",
      "id": "deepimagej/Mt3VirtualStaining",
      "download_url": "https://zenodo.org/record/4290839/files/mt3_virtual_staining.bioimage.io.model.zip",
      "links": [
        "deepimagej/deepimagej",
        "imjoy/BioImageIO-Packager"
      ],
      "format_version": "0.3.0",
      "name": "Masson\u2019s Trichrome Virtual Staining (GAN)",
      "description": "A trained GAN to transform wide-field autofluorescence images of unlabelled tissue sections into images that are equivalent to the bright-field images of histologically stained versions of the same samples.",
      "cite": [
        {
          "text": "Hongda Wang, Yair Rivenson, et al., Nature Biomedical Engineering, 2019",
          "doi": "https://doi.org/10.1038/s41551-019-0362-y"
        }
      ],
      "authors": [
        "Yair Rivenson",
        "Hongda Wang",
        "Aydogan Ozcan"
      ],
      "documentation": "https://innovate.ee.ucla.edu",
      "covers": [
        "exampleImage.png",
        "resultImage.png"
      ],
      "tags": [
        "deepimagej",
        "GAN",
        "histology",
        "Virtual staining"
      ],
      "license": "CC BY 4.0",
      "error": {}
    },
    {
      "type": "model",
      "attachments": {
        "files": [
          "./preprocessing.txt",
          "./postprocessing.txt",
          "./exampleImage.tif",
          "./resultImage.tif"
        ]
      },
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/jones_virtual_staining/model.yaml",
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/jones_virtual_staining",
      "id": "deepimagej/JonesVirtualStaining",
      "download_url": "https://zenodo.org/record/4290839/files/jones_virtual_staining.bioimage.io.model.zip",
      "links": [
        "deepimagej/deepimagej",
        "imjoy/BioImageIO-Packager"
      ],
      "format_version": "0.3.0",
      "name": "Jones Virtual Staining (GAN)",
      "description": "A trained GAN to transform wide-field autofluorescence images of unlabelled tissue sections into images that are equivalent to the bright-field images of histologically stained versions of the same samples.",
      "cite": [
        {
          "text": "Hongda Wang, Yair Rivenson, et al., Nature Biomedical Engineering, 2019",
          "doi": "https://doi.org/10.1038/s41551-019-0362-y"
        }
      ],
      "authors": [
        "Yair Rivenson",
        "Hongda Wang",
        "Aydogan Ozcan"
      ],
      "covers": [
        "exampleImage.png",
        "resultImage.png"
      ],
      "tags": [
        "deepimagej",
        "GAN",
        "histology",
        "Virtual staining"
      ],
      "documentation": "https://innovate.ee.ucla.edu",
      "license": "CC BY 4.0",
      "error": {}
    },
    {
      "type": "model",
      "attachments": {
        "files": [
          "./preprocessing.txt",
          "./postprocessing.txt",
          "./exampleImage.tiff",
          "./Results.csv",
          "./resultImage.tiff"
        ]
      },
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/u-net_hela_segmentation/model.yaml",
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/u-net_hela_segmentation",
      "id": "deepimagej/UNet2DHeLaSegmentation",
      "links": [
        "deepimagej/deepimagej",
        "imjoy/BioImageIO-Packager"
      ],
      "download_url": "https://zenodo.org/record/4155785/files/deepimagej_u-net_hela_segmentation.zip",
      "format_version": "0.3.0",
      "name": "HeLa DIC Cell Segmentation (U-Net)",
      "description": "DeepImageJ compatible U-Net trained to segment Hela cells in 2D phase contrast microscopy images",
      "cite": [
        {
          "text": "Ronneberger O. et al., MICCAI 2015",
          "doi": "https://doi.org/10.1007/978-3-319-24574-4_28"
        },
        {
          "text": "Ulman V. et al., Nature Methods 2017",
          "doi": "https://doi.org/10.1038/nmeth.4473"
        }
      ],
      "authors": [
        "Jo\u00e3o Soares Lopes"
      ],
      "documentation": "https://deepimagej.github.io/deepimagej/models_documentation.html",
      "covers": [
        "unet_hela_seg.jpg"
      ],
      "tags": [
        "deepimagej",
        "segmentation",
        "hela cells",
        "phase contrast"
      ],
      "license": "BSD-2",
      "git_repo": "https://github.com/deepimagej/python4deepimagej/tree/master/unet",
      "error": {}
    },
    {
      "type": "model",
      "attachments": {
        "files": [
          "./preprocessing.txt",
          "./postprocessing.txt",
          "./exampleImage.tiff",
          "./Results.csv",
          "./resultImage.tiff"
        ]
      },
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/u-net_glioblastoma_segmentation/model.yaml",
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/u-net_glioblastoma_segmentation",
      "id": "deepimagej/UNet2DGlioblastomaSegmentation",
      "download_url": "https://zenodo.org/record/4155785/files/deepimagej_u-net_glioblastoma_segmentation.zip",
      "links": [
        "deepimagej/deepimagej",
        "imjoy/BioImageIO-Packager"
      ],
      "format_version": "0.3.0",
      "name": "Glioblastoma Phase Contrast Cell Segmentation (U-Net)",
      "description": "DeepImageJ compatible U-Net trained to segment 2D phase contrast microscopy images of glioblastoma-astrocytoma U373 cells on a polyacrylamide substrate.",
      "cite": [
        {
          "text": "Ronneberger O. et al., MICCAI 2015",
          "doi": "https://doi.org/10.1007/978-3-319-24574-4_28"
        },
        {
          "text": "Ulman V. et al., Nature Methods 2017",
          "doi": "https://doi.org/10.1038/nmeth.4473"
        }
      ],
      "authors": [
        "Jo\u00e3o Soares Lopes"
      ],
      "documentation": "README.md",
      "covers": [
        "cover_image.jpg"
      ],
      "tags": [
        "deepimagej",
        "glioblastoma cells",
        "phase contrast",
        "segmentation"
      ],
      "license": "BSD-2",
      "git_repo": "https://github.com/deepimagej/python4deepimagej/tree/master/unet",
      "error": {}
    },
    {
      "type": "model",
      "attachments": {
        "files": [
          "./preprocessing.ijm",
          "./postprocessing_LocalMaximaSMLM.ijm",
          "./exampleImage.tiff",
          "./Localizations_resultImage_max.csv",
          "./resultImage.tiff",
          "./DeepSTORM4stacksThunderSTORM.ijm",
          "./postprocessing_AveragedMaximaSMLM.ijm"
        ]
      },
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/deepstorm_zerocostdl4mic/model.yaml",
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/deepstorm_zerocostdl4mic",
      "id": "deepimagej/DeepSTORMZeroCostDL4Mic",
      "download_url": "https://zenodo.org/record/4155785/files/DeepImageJ_DeepSTORM_ZeroCostDL4Mic.zip",
      "links": [
        "zero/Notebook_Deep-STORM_2D_ZeroCostDL4Mic_DeepImageJ",
        "deepimagej/deepimagej",
        "imjoy/BioImageIO-Packager"
      ],
      "format_version": "0.3.0",
      "name": "Glial Cell SMLM (DeepSTORM - ZeroCostDL4Mic)",
      "description": "A trained Deep-STORM model for image reconstruction from high-density single-molecule localization microscopy (SMLM).",
      "cite": [
        {
          "text": "Nehme E. et al., Optica 2018",
          "doi": "https://doi.org/10.1364/OPTICA.5.000458"
        },
        {
          "text": "Lucas von Chamier et al. biorXiv 2020",
          "doi": "https://doi.org/10.1101/2020.03.20.000133"
        },
        {
          "text": "G\u00f3mez de Mariscal et al. bioRxiv 2019",
          "doi": "https://doi.org/10.1101/799270"
        }
      ],
      "authors": [
        "ZeroCostDL4Mic team",
        "DeepImageJ team"
      ],
      "git_repo": "https://github.com/HenriquesLab/ZeroCostDL4Mic",
      "documentation": "https://deepimagej.github.io/deepimagej",
      "covers": [
        "input.png",
        "zoom.png"
      ],
      "tags": [
        "zerocostdl4mic",
        "image reconstruction",
        "deepimagej",
        "SMLM",
        "super-resolution"
      ],
      "license": "MIT",
      "error": {}
    },
    {
      "type": "model",
      "attachments": {
        "files": [
          "./preprocessing.ijm",
          "./exampleImage.tif",
          "./resultImage.tif"
        ]
      },
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/3du-net_zerocostdl4mic/model.yaml",
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/3du-net_zerocostdl4mic",
      "id": "deepimagej/3DUNetZeroCostDL4Mic",
      "download_url": "https://zenodo.org/record/4155785/files/3DUNet_ZeroCostDL4Mic.bioimage.io.model.zip",
      "links": [
        "deepimagej/deepimagej",
        "zero/Notebook_U-Net_3D_ZeroCostDL4Mic_DeepImageJ",
        "imjoy/BioImageIO-Packager"
      ],
      "format_version": "0.3.0",
      "name": "3D U-Net - ZeroCostDL4Mic",
      "description": "3D U-Net trained using ZeroCostDL4Mic notebooks to segment mitochondria in Transmission Electron Microscopy (TEM) data.",
      "cite": [
        {
          "text": "Lucas von Chamier et al. bioRxiv 2020",
          "doi": "https://doi.org/10.1101/2020.03.20.000133"
        },
        {
          "text": "\u00d6zg\u00fcn \u00c7i\u00e7ek et al., MICCAI 2016",
          "doi": "https://doi.org/10.1007/978-3-319-46723-8_49"
        }
      ],
      "authors": [
        "DeepImageJ team"
      ],
      "documentation": "https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki",
      "covers": [
        "exampleImage.gif"
      ],
      "tags": [
        "ZeroCostDL4Mic",
        "deepimagej",
        "deepimagej-beta",
        "TEM",
        "segmentation",
        "mitochondria",
        "3DUNet"
      ],
      "license": "MIT",
      "git_repo": "https://github.com/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/U-Net_3D_ZeroCostDL4Mic.ipynb",
      "error": {}
    },
    {
      "type": "model",
      "attachments": {
        "files": [
          "./preprocessing.ijm",
          "./postprocessing.ijm",
          "./exampleImage.tif",
          "./resultImage.tif"
        ]
      },
      "source": "https://raw.githubusercontent.com/deepimagej/models/master/2du-net_zerocostdl4mic/model.yaml",
      "root_url": "https://raw.githubusercontent.com/deepimagej/models/master/2du-net_zerocostdl4mic",
      "id": "deepimagej/2DUNetZeroCostDL4Mic",
      "download_url": "https://zenodo.org/record/4155785/files/DeepImageJ_2D%20UNet_ZeroCostDL4Mic.zip",
      "links": [
        "zero/Notebook_U-Net_2D_ZeroCostDL4Mic_DeepImageJ",
        "deepimagej/deepimagej",
        "imjoy/BioImageIO-Packager"
      ],
      "format_version": "0.3.0",
      "name": "2D UNet - ZeroCostDL4Mic",
      "description": "2D U-Net trained for binary segmentation using the EM images of neuronal membranes and segmentation masks from the ISBI segmentation challenge 2012.",
      "cite": [
        {
          "text": "Ronneberger O. et al., MICCAI 2015",
          "doi": "https://doi.org/10.1007/978-3-319-24574-4_28"
        },
        {
          "text": "Lucas von Chamier et al. bioRxiv 2020",
          "doi": "https://doi.org/10.1101/2020.03.20.000133"
        },
        {
          "text": "G\u00f3mez de Mariscal et al. bioRxiv 2019",
          "doi": "https://doi.org/10.1101/799270"
        }
      ],
      "authors": [
        "ZeroCostDL4Mic team",
        "DeepImageJ team"
      ],
      "git_repo": "https://github.com/HenriquesLab/ZeroCostDL4Mic",
      "documentation": "https://deepimagej.github.io/deepimagej",
      "covers": [
        "cover.png"
      ],
      "tags": [
        "deepimagej",
        "segmentation",
        "zerocostdl4mic",
        "unet"
      ],
      "license": "MIT",
      "error": {}
    }
  ]
}